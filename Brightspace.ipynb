{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This little program enables the autoimation of grade collection, checking for upcoming due dates and maybe something else if I get a request or an idea. \n",
    "Requirements:\n",
    "Selenium: https://pypi.org/project/selenium/\n",
    "Numpy: https://pypi.org/project/numpy/\n",
    "Pandas: https://pypi.org/project/pandas/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets up the webdriver. This only works in firefox HOWEVER you can use chrome using this instead: \n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(options=options)\n",
    "**note that I havent tested it in chrome. not all web drivers are the same so your milage may vary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "options = webdriver.FirefoxOptions()\n",
    "driver = webdriver.Firefox(options=options)\n",
    "options.add_argument(\"-headless\")\n",
    "options.add_argument('--no-sandbox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This here sets up the base url of brightspace \"https://schoolspecific.brightspace.com\" is the typical url base. It also sets up the various buttons that need to be clicked though to get through MSFT login. the getPass import is a input that is passed to your password variable in order to keep it out of the source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass # so you don't show your password in the sourcecode\n",
    "email = 'w0499673@campus.nscc.ca'\n",
    "base_url = 'https://nscconline.brightspace.com'\n",
    "password = getpass.getpass()\n",
    "email_field = (By.ID, 'i0116')\n",
    "password_field = (By.ID, 'i0118')\n",
    "next_button = (By.ID, 'idSIButton9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This just runs through the MSFT login process inorder to get to the brightspace homepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(base_url)\n",
    "WebDriverWait(driver,10).until(EC.element_to_be_clickable(email_field)).send_keys(email)\n",
    "WebDriverWait(driver,10).until(EC.element_to_be_clickable(next_button)).click()\n",
    "WebDriverWait(driver,10).until(EC.element_to_be_clickable(password_field)).send_keys(password)\n",
    "WebDriverWait(driver,10).until(EC.element_to_be_clickable(next_button)).click()\n",
    "WebDriverWait(driver,10).until(EC.element_to_be_clickable(next_button)).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block Iterates through a list of validated grade page urls. Nested loop then extracts the <table> contents from the HTML on each page. the second for loop removes the \"Points\" and the \"comments and asscessments\" column from each list dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_extensions = [\"/d2l/lms/grades/my_grades/main.d2l?ou=299885\",#Networking\n",
    "                     \"/d2l/lms/grades/my_grades/main.d2l?ou=297335\",#d\n",
    "                     \"/d2l/lms/grades/my_grades/main.d2l?ou=295501\",#295501\n",
    "                     \"/d2l/lms/grades/my_grades/main.d2l?ou=295683\",#WEBDEV\n",
    "                     \"/d2l/lms/grades/my_grades/main.d2l?ou=297213\"#Prog\n",
    "                    ]\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "url = []\n",
    "df = []\n",
    "new_df=[]\n",
    "#Iterates through list of grade page urls. Nested loop then extracts the <table> contents from the HTML on each page\n",
    "for each in grades_extensions:\n",
    "    url = base_url + each\n",
    "    driver.get(url)\n",
    "    \n",
    "    for x in url:\n",
    "        tbl = io.StringIO(driver.find_element(By.CSS_SELECTOR,\".d2l-grid-wrapper\").get_attribute('outerHTML'))\n",
    "        df  = pd.read_html(tbl)\n",
    "    #This clears out the columns \"Points\" and \"Comments and Assessments\". \n",
    "    for i in df:\n",
    "        i.pop(\"Points\")\n",
    "        i.pop(\"Comments and Assessments\")\n",
    "        new_df.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block splits each course dataframe into separate dataframes and writes each to a .csv file for easy convenience on checking for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CsvFiles/Networking.csv already exists. Moving on...\n",
      "./CsvFiles/DataFund.csv already exists. Moving on...\n",
      "./CsvFiles/Osys.csv already exists. Moving on...\n",
      "./CsvFiles/Webdev.csv already exists. Moving on...\n",
      "./CsvFiles/Prog.csv already exists. Moving on...\n",
      "./CsvFiles/parent.csv already exists. Moving on...\n"
     ]
    }
   ],
   "source": [
    "csv_file_folder = \"./CsvFiles/\"\n",
    "try:\n",
    "    os.mkdir(csv_file_folder)\n",
    "\n",
    "    #Networking\n",
    "    df0 = new_df[0]\n",
    "    if os.path.isfile(\"./CsvFiles/Networking.csv\") == True:\n",
    "        print(f'./CsvFiles/Networking.csv already exists. Moving on...')\n",
    "    else:\n",
    "        df0.to_csv(\"./CsvFiles/Networking.csv\",index=False)\n",
    "\n",
    "    #DATA FUND\n",
    "    df1 = new_df[1]\n",
    "    if os.path.isfile(\"./CsvFiles/DataFund.csv\") == True:\n",
    "        print(f'./CsvFiles/DataFund.csv already exists. Moving on...')\n",
    "    else:\n",
    "        df1.to_csv(\"./CsvFiles/DataFund.csv\",index=False)\n",
    "\n",
    "\n",
    "    #OSYS\n",
    "    df2 = new_df[2]#OSYS\n",
    "    if os.path.isfile(\"./CsvFiles/Osys.csv\") == True:\n",
    "        print(f'./CsvFiles/Osys.csv already exists. Moving on...')\n",
    "    else:\n",
    "        df2.to_csv(\"./CsvFiles/Osys.csv\",index=False)\n",
    "\n",
    "\n",
    "    #WEBDEV\n",
    "    df3 = new_df[3]#\n",
    "    if os.path.isfile(\"./CsvFiles/Osys.csv\") == True:\n",
    "        print(f'./CsvFiles/Webdev.csv already exists. Moving on...')\n",
    "    else:\n",
    "        df3.to_csv(\"./CsvFiles/Webdev.csv\",index=False)\n",
    "\n",
    "    #Programming  \n",
    "    df4 = new_df[4]\n",
    "    if os.path.isfile(\"./CsvFiles/Prog.csv\") == True:\n",
    "        print(f'./CsvFiles/Prog.csv already exists. Moving on...')\n",
    "    else:\n",
    "        df4.to_csv(\"./CsvFiles/Prog.csv\",index=False)\n",
    "\n",
    "    #Concatenating all dataframes to a csv file. Not super needed but helps to view the data. \n",
    "    if os.path.isfile(\"./CsvFiles/parent.csv\") == True:\n",
    "        print(f'./CsvFiles/parent.csv already exists. Moving on...')\n",
    "    else: \n",
    "        pd.concat([df0,df1,df2,df3,df4], axis=1).to_csv(\"./CsvFiles/parent.csv\", index=False)\n",
    "except FileExistsError:\n",
    "    print(f'Exiting..')\n",
    "    driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
